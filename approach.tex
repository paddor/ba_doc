% vim: ft=tex
\chapter{Approach}\label{ch:approach}
This chapter describes the approach taken by the students to fulfill the
requirements. An introductory overview of all changes in retrospect is given in
\autoref{sec:approach:overview}.

Prototypes developed as proof-of-concepts are explained in
\autoref{sec:approach:prototypes}.

The \autoref{sec:approach:testing} shows the comprehensive testing
infrastructure set up to test all contributions.

The exact approach taken to develop every feature can be found in
\autoref{sec:approach:federation} and the following sections.


\section{Overview}\label{sec:approach:overview}
Numerous changes throughout Roadster's three architectural layers have been
performed. This section summarizes them quickly, before the rest of the chapter
goes into detailed descriptions regarding testing techniques, porting Roadster
to a new \zmq binding, developing the prototypes, and how each required feature
was designed and implemented exactly.

With the exception of the tests, almost all of these changes took place within
Roadster's \sh{lib} directory.

\subsection{Reactor layer}
The following actor classes have been added to allow a hierarchical inter-node
communication with a supernode, subnodes, and a HA peer node:
\begin{description}
	\item [\sh{Roadster::Actors::Upstream}] Registers sockets to communicate with a supernode.
	\item [\sh{Roadster::Actors::Downstream}] Registers sockets to communicate with subnodes.
	\item [\sh{Roadster::Actors::BStar}] Registers sockets to communicate with the \gls{HA} peer.
\end{description}
The above mentioned inter-node sockets are registered in addition to the sockets of a normal COMM actor.
The CORE actor \sh{Roadster::Actors::Core} has been adapted to start the
appropriate set of actors, depending on the actual federation topology
configured.

The module \sh{Roadster::Actors::Codecs}, which performs the serialization and
deserialization of messages when they're sent/received on a socket, has been
moved down from the messaging layer and extended with message authentication.
The new class \sh{Roadster::Actors::MessageAuthenticator} performs the actual
process of generating and verifiying cryptographic signatures.

\subsection{Messaging layer}
The following new protocols have been added:
\begin{description}
	\item [\sh{Roadster::Messaging::FCP}] The Federation Communication
		Protocol. The initial purpose was prototyping inter-node
		message passing. Eventually it is used for ping/pong
		heartbeating, as well as routing messages through nodes to
		arbitrary actors.

	\item [\sh{Roadster::Messaging::BSP}] The Binary Star Protocol. High
		availability mechanisms use it to perform heartbeating and
		communicate the current state within two HA peer nodes.

\end{description}

Analogous to the reactor layer, the following handler classes have been added:
\begin{itemize}
	\item \sh{Roadster::Messaging::Handlers::Upstream}
	\item \sh{Roadster::Messaging::Handlers::Downstream}
	\item \sh{Roadster::Messaging::Handlers::BStar}
\end{itemize}
The exact set of protocols used and supported by each actor are enabled in the
definitions of these handler classes.

Minor changes to two further classes of the messaging layer were necessary to
allow specifying a destination node (in addition to the actor name) as the
recipient of a message, and enable message routing using the new Federation
Communication Protocol.


\subsection{Engine layer}
The following engine classes have been added:
\begin{description}
	\item [\sh{Roadster::Engines::Upstream}]
		Implements mechanisms such as answering pings from the
		supernode with pongs, sending DIM updates to the supernode, and
		providing the lower layers with cryptographic keys to enable
		secure communications.

		If the supernode is configured to be a \gls{HA} cluster,
		this engine helps initiating a failover when necessary.

	\item [\sh{Roadster::Engines::Downstream}]
		Periodically pings subnodes, publishes DIM updates to all
		direct subnodes, and provides cryptographic keys to secure
		communication with subnodes.


	\item [\sh{Roadster::Engines::BStar}]
		The exact high availability mechanisms are implemented here.
		Just like the Downstream and Upstream engines of a supernode
		and its subnodes, the two instances of this engine continuously
		stay in contact to determine which HA peer is active, which one
		stays passive, and recognize the situation where one of them
		becomes unresponsive.
\end{description}

Common CSP functionality has been extracted into the mix-in \sh{Roadster::Engines::CSPMethods}.


\section{Prototypes}\label{sec:approach:prototypes}
As a way of getting familiar with the Roadster code base, as well as to prove
the concepts worked out during the first elaboration iteration, two prototypes have
been developed during the coming elaboration iterations. Andy Rohr, as the
main author of Roadster, was immensely helpful by giving an introduction to
the code base early on.  Although quite overwhelming, the first impression was
that the code is clean, makes good use of abstractions and has loosely coupled
classes.

The two prototypes, namely the inter-node communication and the high availability
mechanism, have been developed with the idea of "cheap, quick, and dirty" in mind. This
allows experimentation and minimizes the cost of failure.
The approach to these two prototypes are described briefly in the next two sections.


\subsection{Inter-node communication}
The idea of this prototype is to achieve rudimentary communication between two
Roadster nodes.

To do so, two new actors need to be added for the communication with neighboring nodes of the
federation.  Since COMM actors are used to communicate with systems outside of
a node, the new actors are:
\begin{description}
\item [COMM.UPSTREAM]\hfill\\
This actor is responsible for communication with the direct supernode.
\item [COMM.DOWNSTREAM]\hfill\\
This actor is responsible for communication with direct subnodes.
\end{description}

The necessary classes in each architectural layer have been implemented as
subclasses of
\begin{itemize}
\item \sh{Roadster::Actors::Base},
\item \sh{Roadster::Messaging::Handlers::Base}, and
\item \sh{Roadster::Engines::Base}.
\end{itemize}

To send messages via new actors, the new protocol \gls{FCP} has been defined.
Encompassing a single message type \sh{Roadster::Messaging::FCP::Messages::Hello}, it provides a
simple means to prototype rudimentary inter-node communication. The supernode's
API of this protocol (\sh{Roadster::Messaging::FCP::API::Supernode}) provides
the ability to send messages of the aforementioned message type to all direct
subnodes via the COMM.DOWNSTREAM actor's PUB \zmq socket.

Running multiple instances of Roadster was fairly simple.
To be able to store the supernode instance's \zmq endpoint somewhere and have
it available to the subnode instance, a new domain model class
\sh{Roadster::Domain::Model::Node} has been defined. The endpoint information
is its only property.

This worked as expected. The reception of the periodic test messages sent by
the supernode's COMM.DOWNSTREAM actor are immediately logged on the subnode's
console.

\paragraph{Evolution} The final version of the FCP protocol includes means to route arbitrary
messages through a federation of nodes to its destination actor, as well as
message types for ping/pong heartbeating. \autoref{sec:approach:msg-routing}
and \autoref{sec:approach:hb} go into more detail.

As described in \autoref{sec:scope:csp}, there are three distinct message flows
in the \gls{CSP}. The same applies to inter-node DIM synchronization. A
supernode with multiple subnodes will act as the server in CSP terminology.

\begin{description}
	\item [COMM.UPSTREAM:]
		This actor's responsibility is to provide a communication
		interface to the supernode. To allow fulfilling its set of
		tasks, it registers three different sockets of type
		DEALER, PUSH, and SUB.

	\item [COMM.DOWNSTREAM:]
		To fulfill its part of the CSP, this actor registers
		three sockets of type ROUTER, PULL, and PUB.
\end{description}


\subsection{High availability}
As suggested by the task description in \autoref{app:task-description}, the
\gls{bstar} has been implemented as two standalone Ruby scripts: One for the
server process, and one for the client process. \gls{cztop} is used as the \zmq
Ruby language binding.

All the client does is periodically send a request to its currently selected
server process along with an increasing number, which the active server simply
echoes. In case no response from the server is received within a certain amount
of time, the client destroys its socket and registers a new one to connect it
to the other server.

Manual tests have shown that it works as expected and reliably. The two server
processes (primary and backup) can be started in any order, immediately start
communicating with each other and determine the one to become active. Killing
the currently active server makes the client to switch and re-send its pending
request to the passive server, which then immediately takes over.


\section{Testing}\label{sec:approach:testing}
This section describes the test methods used to check units, the integration of
multiple components, as well as the behavior of new contributions across the
entire framework.  All test results are described in \autoref{ch:res}.

The following subsections describe in detail how testing is performed.

\subsection{Unit tests}
To ensure the correctness of the implementations, unit tests are written using the test framework
RSpec. 100\% coverage of the students' contributions can be achieved by
adhering to \gls{TDD}, or more specifically, \gls{BDD}. RSpec offers itself as
a valuable testing tool providing expressive assertion and mocking
facilities, as well as more advanced features such as testing spies\footnote{\url{https://github.com/rspec/rspec-mocks\#test-spies}} which
are a perfect use case for Ruby's dynamic binding, a.k.a \emph{duck typing}.\footnote{\url{https://en.wikipedia.org/wiki/Duck_typing}}

Naturally, this also simplifies refactoring the code without the risk of
breaking functionality going unnoticed. Unit tests reside under the \sh{spec}
directory of Roadster's code base.

An example of a typical unit test is shown in \autoref{lst:testing:unit}.

% TODO RSpec extension

\begin{listing}
	\begin{minted}[bgcolor=bg]{Ruby}
module Roadster
  describe Actors::BStar do
    subject { described_class.new messaging_class }
    let(:messaging_class) { double 'messaging handler class', new: messaging }
    let(:messaging) do
      instance_spy Messaging::Handlers::BStar, name: 'messaging_handler_name'
    end

    describe '#publish_message' do
      let(:msg) { Messaging::Messages::Base.new 'sender', 'receiver' }
      it 'publishes message to remote HA peer' do
        expect(subject).to receive(:emit_message).with(:bstar_pub, msg)
        subject.publish_message msg
      end
    end

    describe '#register_ha_sockets' do
      # [...]
    end
  end
end
	\end{minted}
	\caption{Example of two unit tests in RSpec.}
	\label{lst:testing:unit}
\end{listing}


% TODO speccing only public methods and side effects of private methods

% TODO * testing env, specs (~150 -> ~900)



\subsection{Integration tests}
Integration tests verify the interaction between the individual components.
To test new core functionality like federation, high availability, and persistence
synchronization, integration tests have been written.

In order to test the failover or synchronization functionality, individual processes
can simply be killed and restarted later if the scenario defines this.


\subsection{System tests}
System tests are designed to test the application under close-to-reality
conditions, treating the application as a black box: On a certain input, it is
supposed to react with a certain output. The internal mechanisms to produce said
output and reach a certain state are insignificant.

% TODO how to test persistence synchronization

\paragraph{Manual} At times when developing a feature, manual testing can give
useful insights, especially when trouble shooting. Running Roadster manually in
foreground within a terminal session helps with that.  When, for example,
developing a new inter-node protocol, running multiple nodes simultaneously
becomes a necessity. Although on the same development machine, this can be
simulated by starting them as different process groups. Through the
configuration, each Roadster instance is given a different set of endpoints,
e.g. different TCP ports or Unix domain sockets. This is possible and feasible
since \zmq completely abstracts the transport away and thus really doesn't
matter if other Roadster instances are running locally or remotely.

\paragraph{Automated} To create an more realistic environment including real
network conditions, a more lower level approach is taken. Stronger isolation
between Roadster instances can be achieved using software containers. Network
virtualization can be used to induce latency and packet loss to simulate the
properties of a congested network.
Docker and Mininet together provide all of the required functionality.

When a feature depends on external sensor data from a field device (e.g. a \gls{PLC}),
a fake adapter is used. It continually fakes the actions of a fictional robot.

\begin{description}
	\item [Docker:]\hfill\\
		Docker is a container software that makes use of the
		\emph{cgroups}\footnote{\url{https://en.wikipedia.org/wiki/Cgroups}}
		feature of the Linux kernel, which allows the isolation of
		collections of processes. This includes isolation of CPU,
		memory, and I/O usage, as well as process ID and network
		namespaces.

		Docker also provides a programmable way to start with a clean
		state at the beginning of every run of the test suites. All
		state changes and file system modifications are discarded after
		the container is stopped.

	\item [Mininet:]\hfill\\
		Mininet allows creating virtual networks instantaneously.
		Like Docker, it also relies on \emph{cgroups}
		and network namespaces to efficiently run multiple \glspl{VM}
		sharing the same kernel, and provide isolation. These very same
		primitives are used by Docker itself.

		Network infrastructure such as packet switching hardware and
		network links can be modeled in Mininet, including the
		simulation of link quality issues such as induced latency and
		packet loss.

	\item [Fake adapter:]\hfill\\
		A fake implementation of a fictional \gls{PLC}, namely a robot
		that that changes its position randomly in a two-dimensional coordinate
		system serves the purpose of getting external sensor data.
		Using Roadster's guards it will also generate cases as soon as
		it moves out of a predefined, virtual bounding box. This robot
		is implemented using about 15 lines of Ruby code and is part of
		the example application provided by mindclue GmbH.
\end{description}

The system test results from each construction iteration can be found in \autoref{ch:res}.


\subsection{Continuous integration}
\Gls{CI} helps prevent problems when integrating big chunks of code changes,
also known as \emph{integration hell}. A new CI build is triggered upon each
push of changes to the repository using a predefined build script.

\paragraph{GitLab CI} Due to the fact that Roadster's GitHub repository is private, online \gls{CI}
services such as \emph{Travis~CI}\footnote{\url{https://travis-ci.com/}, requires payment after the
first 100 builds} cannot be used without payment. Fortunately,
GitLab\footnote{\url{https://about.gitlab.com}} is a free, open-source GitHub-like development collaboration software and includes CI functionality. It can be installed on private infrastructure, such as the
\gls{VM} provided by HSR, where it has been installed and configured.

\paragraph{Auto triggering} Every push of changes to Roadster or the example application triggers the CI
solution set up on the HSR VM. It then installs Roadster's dependencies, the Roadster
framework itself, the example application, and then runs all of Roadster's test
suites. This is useful to get informed proactively when something breaks.

\subsubsection{Documentation build}
It is deemed bad practice to keep generated files in a Git
repository. Having an additional file to commit is tedious and if done
frequently, it can bloat the repository's commit history since Git treats PDF
files as binary files, and thus cannot use efficient algorithms to work out the
differences only.

This is why compiling the TeX sources for this document is also done reactively
via a pipeline configured on GitLab CI. The resulting artifact, a PDF file, is
then automatically uploaded to Git as a file associated with a newly created
public release. This is done via GitHub's webservice API for managing
releases.\footnote{\url{https://developer.github.com/v3/repos/releases/}}


\subsubsection{Docker container}
To provide a clean test environment for every CI build, a Docker container is used.
It prepares the container with all necessary components before every build
which then runs all test suites. The components include:

\begin{itemize}
	\item Mininet
	\item Ruby
	\item Python
	\item The most recent development version of Roadster (of the appropriate branch)
\end{itemize}

The system tests are run on the GitLab server after each construction
iteration. To do so, the Python scripts set up a virtual network and then start
the appropriate Roadster instances. Some features require a link to fail or a
node to fail, which can be achieved at arbitrary times through Mininet commands or
simply kiling Roadster instances wherever needed. The generated log data is
evaluated later to verify that the behavior for each defined feature is
correct.


\subsubsection{Test scenarios}
Test scenarios are deduced from the features specified in \autoref{ch:reqs}.
They contain configurations for Mininet and the particular Roadster nodes.
The procedure of each scenario is modeled in feature step files. This subsection
describes the implementation and general structure of the test scenarios in detail.


Every run of the system tests is based on the current versions of

\begin{itemize}
	\item The Roadster framework itself
	\item The example application
\end{itemize}

In case the current development is taking place in a feature branch, the same
branch is tried to be checked out in both test working copies. For example to
test a new feature like encryption, it is developed in a feature branch called
\emph{encryption} in Roadster's repository. Because the example application
will need modifications as well (such as the knowledge of public keys for each
node in a federation), it those changes are implemented in a feature branch of
the same name.

A shell script creates the appropriate configuration files (fixtures) before
each test scenario is run and ensures that a directory for each Roadster
instance exists where log data is stored during the run.

Mininet is a Python library. To interactively use Mininet, it makes sense to
implement all system test code in Python. This allows taking influence on the
virtual network and on particular hosts within that network at any time. To
parse and evaluate the features written in the Cucumber format, the \gls{BDD}
framework Behave\footnote{\url{http://pythonhosted.org/behave/}} is used.

\subsubsection{Directory structure}

The directory structure used within the Docker container is illustrated
in~\autoref{lst:testing:docker:directory-structure}.

\begin{listing}
	\begin{minted}[bgcolor=bg]{Shell}
/tmp/
|-- roadster
|   |-- ci
|   |   |-- run_system_tests.sh
|   |   `-- run_unit_tests.sh
|   `-- features
|       |-- autonomy.feature
|       |-- environment.py
|       |-- ...
|       |-- steps
|       |   |-- autonomy.py
|       |   |-- behave_util.py
|       |   `-- ...
|       |-- support
|       |   |-- conf.root.primary.rb
|       |   |-- federation.rb
|       |   `-- ...
`-- projects
	`-- ba-roadster-app
		|-- conf.root.primary.rb
		|-- data.root.primary
		|   |-- eventjournal.tct
		|   `-- parameters.tch
		|-- lib
			|-- domain
			|   |-- federation.rb
			|   `-- ...
			`-- ...
	\end{minted}
	\caption{Directory structure of system tests within Docker container.}
	\label{lst:testing:docker:directory-structure}
\end{listing}

\subsubsection{Roadster federation topology}
The federation used for system tests is build as follows:
\begin{figure}[]
	\center
	\includegraphics[width=0.5\textwidth]{img/logical_federation_setup.pdf}
	\caption{Logical federation topology used in system tests.}
	\label{lst:testing:topo:logic}
\end{figure}

The root node is a HA cluster, which acts as such when appropriate according to
the feature being tested. At other times, only its primary node is active and
thus acts as a non-HA supernode of sN1 and sN2. The naming scheme is enforced
by Mininet and thus somehow clunky and cryptic.

The configuration also dictates that there are two simulated robots running on
subnode sN1, which continually update sensor data in the DIM and create new
cases due to their nature of virtually moving around randomly and thus trying
to escape the bounding box.

Subnode sN2 merely acts as a listener and is not directly supervising any field
devices.

\subsubsection{Virtual network plan}
\begin{figure}[]
	\center
	\includegraphics[width=\textwidth]{img/physical_network_mininet.pdf}
	\caption{Physical federation topology used in system tests.}
	\label{lst:testing:topo:logic}
\end{figure}

All nodes are attached to an \gls{ovs} instance which allows them communicate with each
other via the TCP/IP transport. In addition to this star topology, there is an
additional, dedicated link between the two HA peers which form the root HA
cluster.

%----------------------------------------------------------------------------

\section{Port to new \zmq binding}\label{sec:approach:port}
One of the first changes to Roadster's codebase is porting to a new \zmq
binding. This makes sense for the following reasons:

\begin{itemize}
\item To exclude possible failures from faults in the unmaintained ffi-rzmq\footnote{\url{https://github.com/chuckremes/ffi-rzmq}} library.
\item Encryption is needed later anyway, which is not supported by the currently used library.
\item All other tasks involve \zmq communication anyway.
\end{itemize}

There is currently only a single Ruby package that is maintained, supports
encryption, and is freely available, which is \gls{cztop}. Technically it is a
binding for the \gls{czmq} abstraction library, which is the modern and recommended way of
using \zmq. \autoref{sec:zmq:czmq} explains CZMQ in further detail.

As stated in the task description already, Roadster's event loop makes use of
the \zmq options \sh{ZMQ_FD} and \sh{ZMQ_EVENTS}. Getters for these had to be
added to in CZTop, which was a matter of minutes.

Due to Roadster's software architecture where different concerns
are cleanly separated, all code that actually depended
on ffi-rzmq was located in a single file. The following
things needed to be done:

\begin{itemize}
\item Load CZTop instead of ffi-rzmq.
\item Remove code to manually send and receive the parts of multi-part messages. This has been simplified
in CZMQ and thus is now a single method call.
\item Remove error checking code. CZTop always checks error codes, and raises
an appropriate exception if needed. These exceptions are now translated to Roadster's internal exceptions.
\item Simplify code that deals with \zmq options such as \sh{ZMQ_FD} and \sh{ZMQ_EVENTS}.
\item Replace library calls to use CZTop instead of ffi-rzmq.
\end{itemize}

This was about an hour's work.


%----------------------------------------------------------------------------
\pagebreak
\section{Federation}\label{sec:approach:federation}
Running multiple Roadster nodes can be useful to aggregate information from
several field devices, especially if they cannot be connected to the same node,
possibly because of physical distance. Such a federation of autonomously
running nodes can then aggregate information in the root node, which can then
provide it to higher level client systems. Also, the root node's web UI shall
serve as a centralized point of access to the federation and offer an overview
of it to operational and technical personnel.

A Roadster federation consisting of a root node and two subnodes is illustrated
in \autoref{fig:federation}.
\begin{figure}[]
	\includegraphics[width=\textwidth]{img/federation_protocol.pdf}
	\caption{Federation between a supernode and two subnodes.}
	\label{fig:federation}
\end{figure}

Adding federation functionality to Roadster involves the following aspects:
\begin{itemize}
	\item Means to declare a federation
	\item Message routing
	\item Heartbeating
	\item Inter-node CSP
\end{itemize}

\subsection{Federation definition}
The federation topology has to be defined somewhere. This can be done using a
\gls{DSL} and then put into a static file shared
on all nodes of a Roadster federation. Each actor could then read the file at
startup, just like it is done for other configuration pieces of a Roadster node.

\autoref{lst:dsl:topo:no-ha} shows how such a configuration might look.

To allow the actors of a node to deduce which node they belong to, it is
necessary to provide an additional configuration, e.g. \sh{conf.local_node}.
This option then can be set in the node-specific configuration file as shown in
\autoref{lst:conf:root}.

\begin{listing}
	\begin{minted}[bgcolor=bg]{Ruby}
# Roadster application configuration
module Roadster

  conf.local_node = 'root'

  conf.log_level = ::Logger::Severity::INFO
  conf.pid_file  = File.join conf.root, 'log', 'root.pid'
  conf.log_file  = File.join conf.root, 'log', 'root.log'
  conf.data_path = File.join conf.root, 'data.root'

  conf.webserver_port = 3010
  conf.environment = :development
end
	\end{minted}
	\caption{Node-specific configuration of the node 'root'.}
	\label{lst:conf:root}
\end{listing}

Not every node in a federation is the same: Each one has its own set of field devices (if any).
The configured name of the local node can be used in conjunction with the
federation topology definition to deduce important information such as neighboring
nodes and the exact set of adapters to load on the local node.

\begin{listing}
	\begin{minted}[bgcolor=bg]{Ruby}
module Conf::Federation
  def self.conf
    proc do
      primary_endpoints \
        router: 'tcp://0.0.0.0:20000',
        pull:   'tcp://0.0.0.0:20001',
        pub:    'tcp://0.0.0.0:20002'

      adapters do
        adapter :foobar do
          # config for 'foobar' adapter and its peers
        end
      end

      node :s1 do
        adapters do |s1_node|

          adapter :simu do
            label           'SIMU'
            desc            'Process simulation adapter'
            adapter_class   Roadster::Adapters::Simulation

            peer :robot_controller_01 do
              label 'robot_01'
              uri   ''
            end

            peer :robot_controller_02 do
              label 'robot_02'
              uri   ''
            end
          end
        end

        objects do |s1_node|
          robot :robot_01 do
            label_i18n  de: 'Mein schicker roboter nummer 1',
                        en: 'My fancy robot number 1'
          end
          s1_node.objects.robot_01.reference_peer s1_node.adapters.simu.robot_controller_01

          robot :robot_02 do
            label_i18n  de: 'Mein schicker roboter nummer 2',
                        en: 'My fancy robot number 2'
          end
          s1_node.objects.robot_02.reference_peer s1_node.adapters.simu.robot_controller_02
        end
      end
    end
  end
end
	\end{minted}
	\caption{Federation DSL example without HA.}
	\label{lst:dsl:topo:no-ha}
\end{listing}


\subsubsection{Inter-node sockets}
To provide all functionality used by any of Roadster's messaging protocols, the
new actors from the prototype are completed according to the illustration in
\autoref{fig:federation}. As a result, the COMM.DOWNSTREAM actor registers a
ROUTER, a PULL, and a PUB socket, whereas the COMM.UPSTREAM actor registers a
DEALER, a PUSH, and a SUB socket.

\subsection{Message routing}\label{sec:approach:msg-routing}
Messages need to be sent from an actor on one node to an actor on another node.
The best place to put this logic is the CORE actor which already does this for
messages exchanged within a node. The existing mechanism needs to be extended to take other nodes
into consideration as well. Then messages can be passed around hop-by-hop.

Message routing shall be stateless, following the well-known and battle proved
example of routing in \gls{IP}. This means that even a message sent in
\emph{Dialog} mode shall not leave pending resources acquired on nodes other
than the source and the destination node.


The \sh{Roadster::Messaging::Messages::Base} class has been extended to accept
not only a destination actor as recipient, but also a node. The simplest way
possible, which also happens to be very convenient when writing protocol code,
is to follow the email example, e.g. \sh{actor@node}. The \sh{node} is actually
the full path of a node, starting from the root node. As an example, a message
sent to the CORE actor of the node \sh{root.s1}, the recipient shall be
\sh{core@root.s1}.

If the recipient node is not specified, the local node shall be inserted
automatically upon sending. The same applies to the source node. This is to
ensure that legacy code unaware of the federation feature still works as expected.

Any message that is to be routed shall be sent to the CORE first, which was
already the case before this bachelor thesis. What the CORE now does, is
inspect the message's recipient: If it's destined to the local node, it is
handled as always. Only if the destination node is a remote node, the new
routing logic in \sh{Roadster::Messaging::FCP::Core} comes into action.

Routing within a hierarchical topology is very easy, especially when the
recipient's full path within the hierarchy is part of the message. If the
recipient node's path is not a prefix of the local node, the next hop has to be
the supernode. Otherwise, it has to be one of the subnodes, which is determined easily,
being simply the path one component longer than the one of the local node.

Due to the hierarchical property of Roadster federations, network loops are
definitely not present. This simplifies the routing mechanism further, because
no means of limiting a message's lifetime is necessary, as it is in \gls{IP} in
the form of a time-to-live field. IP needs this mechanisms because network
topologies can change at any time, even creating loops, which could then result
in a packet circulating indefinitely.

Any wrong recipient set in the message results in the message being discarded
immediately by the ROUTER socket if it is not aware of a corresponding remote socket.

 The complete code for this routing algorithm is illustrated in
 \autoref{lst:approach:msg-routing}.


\begin{listing}[H]
	\begin{minted}[bgcolor=bg]{Ruby}
class Core < BaseAPI
  def initialize(messaging)
    super
    @subnode_regex = /^#{Regexp.escape local_node}\.\w+/
    @supernode = local_node.split('.')[ 0 .. -2 ].join('.')
  end

  # Forward message using messaging layer. Either to local actor or to
  # remote node.
  #
  def forward_message(msg)
    if local_node == msg.receiver_node
      # local delivery
      msg.add_envelope msg.receiver
    else
      set_next_hop msg
    end

    messaging.forward_message msg
  end

  private

  # Lookup and set next hop(s) of message using "string based"                                                                                                             # routing. It's either forwarded to the supernode or one of the
  # subnodes.                                                                                                                                                              #
  # @param msg [Messaging::Messages::Base] the message to prepare for                                                                                                      #   the next two hops to another node
  #                                                                                                                                                                        def set_next_hop(msg)                                                                                                                                                      if subnode = msg.receiver_node[ @subnode_regex ]
      # forward to/via subnode
      msg.add_envelope "comm.upstream@#{subnode}"      # second hop
      msg.add_envelope "comm.downstream@#{local_node}" # first hop
    else
      # forward via supernode
      msg.add_envelope "comm.downstream@#{@supernode}" # second hop
      msg.add_envelope "comm.upstream@#{local_node}"   # first hop
    end
  end
end
	\end{minted}
	\caption{Message routing algorithm.}
	\label{lst:approach:msg-routing}
\end{listing}


\subsubsection{Example}
When a user of the root node's web UI wants to change a value on a field device
connected to the root node's subnode, a command is sent from the browser to the
root node's COMM.WEBUI actor. From there it is sent to the CORE actor, which
routes it via the DOWNSTREAM actor to the subnode. There it is relayed by the
COMM.UPSTREAM actor to the the CORE actor, which then routes it locally to the
correct COMM actor, which in turn executes the command on on the field device.

\subsubsection{Heartbeating}\label{sec:approach:hb}
To avoid filling a PUSH socket in case the supernode is unavailable, and also
just to keep an up-to-date view of neighboring node's liveliness, heartbeating
is performed between a supernode and its subnodes.


Two new message types have been defined:
\begin{itemize}
	\item \sh{Roadster::Messaging::FCP::Messages::Ping}
	\item \sh{Roadster::Messaging::FCP::Messages::Pong}
\end{itemize}

Two-way heartbeating (ping/pong) is used, where the supernode periodically
sends a Ping message to all its direct
subnodes. This is done via the COMM.DOWNSTREAM's PUB socket (one-to-many).
Every subnode then replies with a Pong
message, done via the COMM.UPSTREAM's DEALER socket (one-to-one).

Each received Pong message proves to the supernode that the respective subnode
is responsive. Of course, this also applies to the Ping message: Receiving a
Ping message tells the subnode that its supernode is responsive.

The implementation actually sends a sequence number with every Ping message,
which is then echoed as part of the Pong message. This makes it possible to
recognize the situation of a much delayed Pong message, including the
calculation of the exact delay (spanning multiple Ping periods).

Why are Pings not sent in the \emph{Dialog} mode? Dialog messages are not
suitable for one-to-many communications.

The \gls{ZMTP} version 3.1, as supported by recent versions of \zmq, actually
contains a heartbeating feature. But ZMTP 3.1 is not stable yet as of this
writing, and in case a remote socket becomes unresponsive, the connection is
silently disconnected, which is not very useful to keep track of neighboring
nodes' liveliness. Its intended use is to detect stale TCP connections and thus
release possibly blocked processes.

For the aforementioned reasons, application heartbeating is performed.

Due to the message routing being used for the Pong message, the a full cycle of
Ping/Pong involves the following actors, starting with the Ping message:
\begin{enumerate}
	\item COMM.DOWNSTREAM of the supernode
	\item COMM.UPSTREAM  of the subnode
	\item COMM.CORE of the subnode
	\item COMM.UPSTREAM of the subnode
	\item COMM.DOWNSTREAM of the supernode
	\item COMM.CORE of the supernode
	\item COMM.DOWNSTREAM of the supernode
\end{enumerate}

This is good because it means both CORE actors of any supernode-subnode pair
are involved. In case, for some reason, the CORE actor is unresponsive, Ping
messages are not simply echoed by the COMM.UPSTREAM actor, which is the desired
behavior.


\subsection{Inter-node CSP}
The DIM has to be replicated across a hierarchical federation of nodes, as the
DIM is the essential data structure representing the overall state of a
Roadster federation.

One of the new actors' responsibility is the replication of updates to the DIM,
similar to how the \gls{CSP} works within a single node.  To do so, both the
COMM.UPSTREAM and COMM.DOWNSTREAM actor simply subscribe to DIM updates within
a node just like any other COMM actor does.  Then they replicate any subsequent
updates over the network to the neighboring nodes. The existing three socket
pairs are used, since they are protocol agnostic thanks to Roadster's layered
architecture.

\paragraph{Replication is bidirectional}
It is possible that two sibling nodes will have performed modifications to the
DIM while they were disconnected from their common supernode. Thus, the initial
exchange of snapshots, as well as the subsequent propagation of modifications
to the DIM has to be bidirectional.

\paragraph{CAP theorem}
The CAP theorem \cite{wp:cap} states that it is impossible for a distributed
computer system to simultaneously provide consistency, availability, and
network partition tolerance. In the face of a network partition, one has to
chose between availability and consistency. Because subsystems of a Roadster
federation must be autonomous, the obvious choice is availability. Eventual
consistency is achieved when recovering from a network partition by simply
reinitiating the DIM replication process.

\subsubsection{Object ownership}
The concept of ownership has to be introduced. Every object within the DIM
shall belong to a particular node. Modifications to the objects shall be done via
that node, and only that node, so the node is the authorative instance for all modifications of its own objects.
For that, every object in the DIM has to have a reference
to the object representing its owner node, which is part of
the configuration that is loaded from the static configuration loaded by every
actor at initialization.

Some objects like parameters (described in \autoref{sec:scope:persistence})
will apply to a whole federation and will thus be owned by the root node.
Examples of these are UI user credentials.

To avoid having to store an additional reference to a node object in every DIM
object, the process of finding its owning node can be simplified by rearranging
the objects. Making all objects direct or indirect children of the owning node
means that determining their owning node is merely a traversing of the tree up
to the first node object.

As a result, the existing domain model class \sh{Roadster::Domain::Model::Root}
has been eliminated. Instead, the root node's
\sh{Roadster::Domain::Model::Node} object takes its place in the DIM. As a
consequence, the whole configuration of adapters, field devices, aggregates,
and such now belong to the root node. Of course, the same goes for any subnodes
and their configuration.

\subsubsection{Degree of replication}
There are several variants when it comes to what exactly of the DIM should be replicated:

\paragraph{Variant 1: Self-subtree only}
Synchronize on subtree only, which means a node only knows the DIM part of
itself. The big disadvantage is that it will not have a copy of the rest of the
DIM, which can be useful to inspect variables on neighboring nodes, especially
when they're unreachable.

\paragraph{Variant 2: Sync complete tree}\label{par:approach:dim:var2}
Always sync on complete tree, which means getting the snapshot from the
supernode and merge the own subtree into it, replacing whatever subtree is
already there. This works because of the autonomy requirement for nodes and
their subnodes. This variant is very easy to implement at first.

\paragraph{Variant 3: Either sync on subtree or complete tree}
Make it configurable: Either sync on subtree or on complete tree. The
topology DSL would allow to specify this property for each node. This is
the best of both worlds, but more effort.

Variant 2 will be the first step, as following the \gls{KISS} principle is one
of the non-functional requirements. Variant 3 will be the second step, if at
all. This depends on whether it will be needed performance-wise.

\subsubsection{Avoiding code duplication}
The \gls{CSP} has to work as an intra-node protocol (within a node, which is
the legacy behavior), as well as an inter-node protocol (within a federation).
That means \gls{CSP}-related server functionality has to be present in the CORE
engine, as well as in the DOWNSTREAM engine. CSP-related client functionality has
to be present in all existing COMM engines, the UPSTREAM engine, \emph{as well
as the DOWNSTREAM engine}, since it also acts as a CSP-client to the CORE engine on
the same node.

To avoid a considerable amount of code duplication, CSP-related functionality
is extracted into its own reusable module, which is then mixed into all
relevant actors. The \emph{Template Method} design pattern is used to handle
the common case of handling a received
\rb{Roadster::Messaging::CSP::Messages::ModelUpdate} message. The hook methods,
called by the template method, are then implemented 
in each particular class where necessary. Where no special behvior is needed,
the mixed-in methods are left unchanged.

\subsubsection{Ignoring update reflections}
Because of the way the \gls{CSP} works, modifications to the \gls{DIM} pushed
to the supernode have to be published back to all subnodes, just like the CORE
actor publishes modifications to back to all local actors. That means the update is
also reflected back to the subnode on which the update originated. A subnode's
UPSTREAM actor has to recognize this situation and discard the update in question
immediately.

This is easily achieved by comparing the version number, because a reflected
update always has a version number $\leqslant$ the local version number.

\subsubsection{Version monotonizing}
In case a node has to be rebooted due to whatever reason, its version numbers
start over at zero.
This leads to the situation where its domain model updates sent to neighboring
nodes are discarded as being outdated, until they reach their previous value.
This is why snapshots from neighboring nodes are initially requested to
instantly increase the version numbers to their previous value.

The implementation is straight-forward. When applaying a snapshot --- as well as regular
updates --- a mere monotonical increase of the version number is enforced by
taking the maximum of the two, no matter if the increase was caused by local or
an foreign snapshot.

\paragraph{Bootstrapping}
When starting an entire federation of nodes, and each node initializes foreign
node versions to zero, the very first update or snapshot from that node would
be recognized as outdated and thus discarded. This is why all
\sh{Roadster::Domain::Model::Node} instances representing foreign nodes are
initialized to version -1, so the very first update ($\geqslant 0$) is always
applied.
% TODO: supernode implementation braucht dieses Funktion auch - weil

\begin{figure}[]
	\includegraphics[width=\textwidth]{img/activity_diagram_upstream.pdf}
	\caption{CSP upstream activity diagram}
	\label{fig:csp:upstream:activty:diagram}
\end{figure}

\begin{figure}[]
	\includegraphics[width=\textwidth]{img/activity_diagram_downstream.pdf}
	\caption{CSP downstream activity diagram}
	\label{fig:csp:downstream:activty:diagram}
\end{figure}

\begin{figure}[]
	\includegraphics[width=\textwidth]{img/sequence_diagram_model_update_pub.pdf}
	\caption{CSP version sequence diagram}
	\label{fig:csp:version:sequence:diagram}
\end{figure}

Beim Start eines Nodes werden die foreign update Versionsnummern auf -1 gesetzt, so
dass der erste Snapshot nicht discarded ist.

\subsection{Access control}
% TODO: DIM access control

\subsection{Remote case management}
% TODO gem 'simple_states' failed and thus was dropped, reduced complexity
% TODO how to write your own FSM


%----------------------------------------------------------------------------
\section{High availability}\label{sec:approach:ha}
If Roadster is going to be run in a federation, measures need to be taken to
mitigate the risk of failure, since many nodes are more likely to fail than a
single node. Availability shall be ensured by
adding redundancy on certain levels of the node hierarchy (e.g. at the bottom
of the topology, or at root level), in the form of a
fully functional backup node in addition to the primary one.

Run together in a hot-standby cluster, the passive node's responsibility is to
take over in case the active one fails to deliver its service.



\subsection{Defining reliability}
When speaking about reliability, it is worth listing the failures the solution must be
able to handle. According to the requirements, and thinking a bit further,
handleable failures of the following three categories have been identified:

\begin{description}
	\item [Hardware failure on the active node:] \hfill\\
		No hardware runs forever. Any of the following things could
		happen spontaneously at any time:

		\begin{itemize}
			\item A non-redundant disk can fail fatally
			\item Memory can encounter an irrecoverable error
			\item The \gls{CPU} catches fire
			\item The node's power supply starts smoking
			\item The node's switch port can break
			\item The node's \gls{NIC} can break
			\item A power or network cable mysteriously fail due to wear and tear
			\item A random power outage that only affects one node
			\item Someone accidentally pulling the node's power
				plug or network cable (human-induced)
		\end{itemize}

	\item [Software failure on the active node:] \hfill\\
		Bug-free software is rare, if it exists at all, and the
		following scenarios are possible:

		\begin{itemize}
			\item Roadster crashes, e.g. the CORE actor becomes unresponsive
			\item the disk becomes full
			\item the memory becomes full (and triggers the \gls{oom-killer})
			\item the whole OS freezes or crashes (less likely, but possible)
			\item Accidental shutdown of the currently active HA
				peer, either just the Roadster application, or
				the whole node (human-induced)
		\end{itemize}

		More about handling crashes of certain actors can be found in
		\autoref{sec:approach:ha:hb}.

	\item [Network failure:] \hfill\\
		This only includes:
		\begin{itemize}
			\item Failure of the link connecting a HA node to the
				rest of the federation.
			\item Configuration mistakes in
				switching/routing/firewall equipment which cut
				off the currently active HA peer (human-induced)
		\end{itemize}
\end{description}

Handling a failure means an actual service interruption can be avoided.

\subsubsection{Failures not handled}
Failures that do not have to be or cannot feasibly be handled include:

\begin{description}
	\item [Link failure between a subnodes and one of the HA peers:]\hfill\\

		This cannot be handled since the two HA peers would have to
		continually share the number of subnodes connected to them, and
		based on that, make a decision on which one should be active or
		passive. Since the link between them could fail as well, this
		decision cannot be done reliably, which could lead to the
		dreaded split brain syndrome.

		Actually the \gls{bstar} could be extended to support this kind
		of mechanism. The details are described in
		\autoref{sec:approach:ha:bstar-ext}.


	\item [Link failure between a HA peer and a field device:]\hfill\\
		The \gls{bstar} algorithm will not initiate a failover since the
		active peer is still responsive and is able to send heartbeats to the passive node.

		The interrupted communication with the affected field device
		could and definitely should cause an alarm, but no failover,
		since they're only half of the conditions that have to be met
		for a failover.

		\autoref{sec:discussion:ha:manual-failover} describes a
		proposal for manually induced failovers.

	\item [ Complete network outage:]\hfill\\
		A complete network outage, such as caused by a routing or
		firewall configuration mistake, cannot be handled gracefully by
		Roadster.

	\item [ Non-redundant hardware failure:]\hfill\\
		In case non-redundant hardware fails, such as a whole network
		switch, cannot be handled gracefully by Roadster.

	\item [ Complete power outage:]\hfill\\
		A complete power outage will not be handled gracefully by
		Roadster. Providing a \gls{UPS} to keep Roadster nodes and
		network equipment up and running in such a case is matter of
		the respective facility in question.

	\item [ Natural disasters:]\hfill\\
		These cannot be handled gracefully by Roadster. Damage from an
		earth quake, a fire, meteorological disasters, solar flares, or
		similar, are outside of the scope of Roadster's high
		availability feature.
\end{description}

The \gls{zguide} describes a very simple mechanism to achieve this kind of high
availability with exactly two redundant nodes: The \gls{bstar}. It
provides a set of clients a highly available service by running two server
nodes in a hot-standby setup. It is simple and thus very robust, takes measures to avoid the
split-brain syndrome, and is fairly easy to implement, even as reusable
code.

The implementation could be contained within a new kind of COMM actor
called BSTAR. This makes sense since, in a way, it talks to the outside world.
That part of the outside world just happens to speak the same language. This
means that the new kind of actor most likely will not need an adapter like COMM
actors usually do in Roadster.

\subsection{Binary Star in a nutshell}
Two HA peers are started either as primary or as backup. After an initial
handshake, the primary one becomes active, the backup node becomes passive. The
two continually exchange heartbeats (and their current state with regards to
the \gls{bstar}). Clients always connect to the primary node's endpoint first. This
is illustrated in \autoref{fig:ml:ha}.

\begin{figure}[]
	\includegraphics[width=\textwidth]{img/ML-HA_bstar.pdf}
	\caption{Schema of HA cluster and a higher level client.}
	\label{fig:ml:ha}
\end{figure}

\begin{figure}[]
	\includegraphics[width=\textwidth]{img/state_machine_diagram_bstar.pdf}
	\caption{BStar machine state diagram}
	\label{fig:bstar:state:diagram}
\end{figure}

\subsubsection{Socket types}
The sockets used by both HA peers to send and receive heartbeats and state
updates is a PUB-SUB pair each. Using PUB-SUB sockets makes sense to avoid queues filling up
in case of an actual failure, which PUSH-PULL sockets would do. PUB sockets simply drop messages when there are
no SUB sockets connected, which is the desired effect.


\subsubsection{Configuration}
The DSL has been extended to support an additional property called
\sh{backup_endpoints}. Furthermore, the hashmaps stored in the properties for
the primary and backup endpoints simply contain another endpoint each: The ones
used by the COMM.BSTAR actors. This is illustrated in \autoref{lst:dsl:topo:with-ha}.
Using this information, direct subnodes of a HA-node can determine the correct
supernode, as well as know the other node's endpoints in case the currently
active HA peer fails.



\begin{listing}
	\begin{minted}[bgcolor=bg]{Ruby}
module Conf::Federation
  def self.conf
    proc do
      primary_endpoints \
        router: 'tcp://0.0.0.0:20000',
        pull:   'tcp://0.0.0.0:20001',
        pub:    'tcp://0.0.0.0:20002',
        ha_pub: 'tcp://0.0.0.0:20003'

      backup_endpoints \
        router: 'tcp://0.0.0.0:20010',
        pull:   'tcp://0.0.0.0:20011',
        pub:    'tcp://0.0.0.0:20012',
        ha_pub: 'tcp://0.0.0.0:20013'

      adapters do
        # telnet server for client systems (fake OPC-UA HA interface)
        adapter :telnet do
          label           'Telnet'
          desc            'Telnet Server'
          adapter_class   Roadster::Adapters::TelnetServer

          peer :server do
            label   'LTA'
            desc    'LTA'
            uri     "tcp://0.0.0.0:#{Roadster.conf.telnet_server_port}"
          end
        end
      end

      node :s1 do
        # [...]
      end
    end
  end
end
	\end{minted}
	\caption{Federation DSL example with HA.}
	\label{lst:dsl:topo:with-ha}
\end{listing}



\subsubsection{OPC UA}
One of the non-functional goals demanded the HA solution be developed with
\gls{opc-ua} in mind. OPC-UA describes several ways of non-transparent server
redundancy, which seems to map closely to how the \gls{bstar} works.

\subsection{Failover}
The passive node takes over when the following two conditions are met:

\begin{enumerate}
\item No life signs from the active node
\item Connection requests from clients
\end{enumerate}

The second condition is to prevent the split-brain syndrome and thus can be
thought of as an external vote for the node to actually initiate the failover.
This works because clients will try to (re-)connect to the HA peers in
round-robin fashion.  This algorithm is explained in \cite[Chapter 4 - Reliable
Request-Reply Patterns, Client-Side Reliability (Lazy Pirate
Pattern)]{zmq:zguide}.
% TODO: add Ruby example

In case the currently active peer crashes, the two conditions will be met.
This means that the passive node starts accepting snapshot requests (ICANHAZ
messages) and updates the DIM, so every other node will know about the new,
active node. This is needed for the message routing to work.

To establish or destroy connections (either to other nodes or to field
devices), callbacks from the \gls{bstar} library can be used to react on
becoming active and becoming passive. To do something in another actor,
Roadster's messaging infrastructure can be used.

% TODO Going active:
% * Core: guards (cases), ...
% * IoComm: peer connections
% * Downstream: subnode pinging, CSP publishing
% * Upstream: CSP pushing to supernode
% * Storage: ?
% * Logger: -


% TODO: Going passive
% TODO passive node: why not Ping subnodes too? Upstream sockets would have to be
%  connected to two nodes. => implement ROUTER-ROUTER


\subsubsection{No client, no failover}
A failover can only happen if there is at least one client. With no clients, a
vote cannot happen. Thinking about it, it is not a bad thing if the failover
cannot happen in that case, since there is no client depending on the service
brought by a HA cluster.

\subsubsection{Alarm generation}
% TODO using Guard
When a failover happens, it makes sense to create an alarm case in the
DIM, so the outage is visible to operational personnel in one of the web UIs.
The same applies to the case where the passive node goes down, although it
does not have an immediate effect on availability.  This is so the operational
personnel can act upon the alarm and e.g. initiate field forces to inspect the
failed node and repair it.

Once repaired, it is restarted with the exact same configuration --- either primary
or backup. Since there is already an active node (either the primary one,
or the backup one), the newly repaired node will become the new passive node.

\subsubsection{Failover from backup to primary node}
Once failed over, the newly active backup node stays active. It does so until it
fails itself or is manually stopped. It never automatically switches back to
make the primary node the new active one without a failure. This is key. If a
node becomes unreachable, the failover happens automatically, but anything else will
require human interaction.

Subsequently, when the previously broken, primary node has been repaired, it
rejoins the \gls{bstar} cluster as the passive node. At that point, the backup
node can be killed if need be, and the primary node will take over again.  This
works because the \gls{bstar} operates symmetrically after a successful
handshake during initialization.

\subsection{Replication}
% diagonal HA
The passive HA peer needs to stay up-to-date, e.g. take part in DIM
synchronization. Instead of clients replicating modifications to both HA peers, as
described in \cite[Chapter 5 - Advanced Pub-Sub Patterns, The Clustered Hashmap
Protocol]{zmq:zguide}, the passive HA peer could just act as a supernode to the
active HA peer. This eliminates the need for an additional protocol. In case of
a failover, the roles of course need to be exchanged.

% TODO: what if HA cluster has supernode
{\color{red}A problem would be the case where the HA cluster has a supernode (although
considered an unusual case). That would mean the active peer has two supernodes
connected at the same time, which is not supported by the planned communication
infrastructure (especially with encryption, see
\autoref{sec:approach:encryption:ha}).  A solution could be to perform the
replication to the HA peer only via sockets of the two BSTAR actors.}

\subsection{Rolling upgrades}
% OPTIMIZE move to Discussion
An obvious side benefit of this comes into play with upgrades. Using the HA
cluster capability it is possible to perform rolling upgrades, meaning one HA
peer can be upgraded while the other one stays in service. After a successful
upgrade, Roadster on the active peer can be stopped, upgraded, and restarted as
the passive peer.

\subsection{A note on dedicated links}
The \gls{zguide} mentions that a dedicated network link between the two HA peers
(traditionally done with a crossover cable) is the best solution to prevent the
split-brain syndrome. This is true. But in some cases, it could also prevent a
failover from happening.

Imagine part of the currently active peer's network equipment fails, i.e. one
of its \glspl{NIC} connected to the switch fails, or one of its switch ports
fail. In that case it will be unreachable to the rest of the
federation or to the client. A failover would be desired. But it
cannot happen, since heartbeats will still be exchanged with the passive node over
the dedicated link. So it is a trade-off between risking the split-brain
syndrome and not being able to perform a failover.

\subsubsection{Extending the \gls{bstar}}\label{sec:approach:ha:bstar-ext}
% vision
Of course the \gls{bstar} mechanism could be extended to handle cases where the
active peer loses connectivity to its clients, but not to the other HA peer. In
a case like that, the passive node could actually take over to minimize
service downtime. The active HA peer could communicate the number of fully connected clients,
which would be zero in case it is cut off from its clients. That way, the
passive node could recognize the situation correctly, since it will get
requests from clients, which are trying to fallback to the passive peer since
the active peer is unresponsive. Knowing that the active peer has zero
connected clients, it could promote itself to the new active peer.

% what's needed for higher-level clients
For this to work, a way of counting fully connected (not just requesting)
clients has to be introduced. The COMM actor providing the \gls{opc-ua}
interface would know best how many clients are connected. This would solve the problem for single-level HA setups.

% what's needed for subnodes as clients
In case of a multi-level federation with a HA cluster at its root, the
cluster's subnodes form another set of clients. Because nodes within a
federation communicate with each other via \zmq sockets, telling how many
clients are connected is a bit less straight-forward, because \zmq abstracts
connection handling completely away. \zmq declares such needs as application matter.
The subnodes would have to implement application-level heartbeating.
That is, the subnodes that are fully connected at a given point in time (i.e. enrolled
in the DIM replication) would periodically send heartbeats which could then be
used to maintain an up-to-date list of active clients (where stale client
entries automatically expire).  The number of active clients (the size of the
list) could be communicated privately just between the two HA peers, along with
the heartbeats. Publishing that information via the DIM might be problematic,
since DIM updates go over the main network link.

% step down from active to passive
Something else needed is a HA peer's ability to step down from being the
active node as soon as its peer promotes itself to the newly active peer. In
the standard \gls{bstar} mechanism, this would be recognized as the split-brain
syndrome and handled fatally.

% discard because KISS
Doing this without an actual need would be a violation of the KISS principle,
so the first approach will not include any extensions to the \gls{bstar}.

\subsubsection{Corner case}
A highly unlikely, but dangerous corner case \emph{could} lead to the
split-brain syndrome. The following steps would be required to happen:

\begin{enumerate}
	\item The backup node is currently the active one

	\item Then the dedicated link fails, which means no heartbeats are
		exchanged anymore

	\item A new client tries to connect or an existing one is temporarily
		gone and tries to reconnect
\end{enumerate}

Since clients try to contact the primary node first, this could
lead to dreaded the split-brain syndrome. The primary node does not hear any
life signs from the backup node (the rightfully active peer), and client
requests count as votes. This means it will promote itself to the active peer,
even though the backup node is still active.

\subsection{A note on heart beating}\label{sec:approach:ha:hb}
Special attention needs to be paid when it comes to sending heartbeats within a
HA cluster. A na\"ive developer might implement the BSTAR actor so it
autonomously sends heartbeats. This works as long as the failures only affect
the hardware. But what if a software error happens in the CORE actor?  A
Roadster node certainly cannot function without the CORE actor. In that case the
BSTAR actor should not send out heartbeats anymore.

A better implementation would have the BSTAR actor periodically inquire (PING
request) the CORE actor whether it is still healthy, and only send out a
heartbeat in case it gets a response (PONG) in time. This can be done with a
simple mechanism, where the CORE actor is programmed to respond to every PING
request with a PONG response. Similar infrastructure of Roadster could be used
instead, if it already provides it.

Further ideas based on this fundamental mechanism are discussed in
\autoref{sec:discussion:imp:ha:hb}.

%----------------------------------------------------------------------------
\section{Persistence synchronization}\label{sec:approach:psync}
% TODO: big picture
The persisted data and updates to it, handled by the STORAGE actor, need to
bubble up and collected in the root node.

\subsection{Aspects}
There are multiple aspects involved in persistence synchronization:

\begin{description}
	\item [Initial synchronization:]\hfill\\
		How does one get the initial delta of updates since the last
		synchronization?


		\paragraph{Event journal} Event journal data is not
		append-only. Existing cases can still be modified, e.g. to
		confirm them. So the solution to get the full delta of
		modifications, but not more than needed, is to request the
		oldest non-finished case for each owning subnode (direct and
		indirect ones).

		\paragraph{Time series} The good thing about time series is
		that the records, once written, will not be modified. That allows
		for a very simple method of getting new time series records by
		just requesting all records added after a particular point in
		time, per series. However, since old time series data is
		deleted after a certain amount of time (e.g. 6 months), the
		timestamp of oldest record remaining also needs to be requested
		by the supernode, per series, so it can delete them from its
		local files as well.

		\paragraph{Parameters} Every param is owned by a node, and is
		synchronized through the DIM.  What is persisted is merely the
		last updated value so the node is able to boot with not only
		sensible defaults, but actual values that are most likely still
		correct. This means that there is no delta of modifications to
		communicate. Modifications to parameter objects in the DIM just
		need to be persisted.

	\item [Continuous synchronization:]\hfill\\
		Send further updates, one-by-one, in an event-driven manner.
		This is only needed in case the solution aims for event-driven
		(i.e. close to instantaneous) synchronization.

		\paragraph{Event journal} Non-finished cases live in the DIM.
		That means any node could theoretically persist a history of
		all cases owned by its subnodes (direct and indirect ones) by
		itself. Another way would be for any node to only create a
		persisted history its own cases and then communicate the
		modifications to the persisted data to its supernode. Every
		node would in turn include modifications from its subnodes
		(direct and indirect ones) in the stream of modifications to
		its supernode. {\color{red}It is not clear yet, what is the best
		solution here.}\\

		\paragraph{Time series} The most recent values of sensor data
		is held in the DIM. That means any node in the federation could
		do the sampling and persisting of time series data by itself.
		{\color{red}It is not clear yet what is the best solution here.}\\
		The deletion of old records does not have to be bubbled up,
		since that is done by a Roadster node autonomously whenever it
		persists a new one.

	\item [HA peer sync:]\hfill\\
		How is the passive HA peer updated?
		This not only matters when the supernode is a HA cluster (multi
		level), but also when it is at the bottom of the node hieararchy
		(single level).

		% diagnoal HA
		Same as with the DIM synchronization between HA peers, this
		could be done by simply treating the passive HA peer as a
		supernode.
\end{description}


\subsection{Variants}
There are multiple variants to achieve the needed functionality.

\subsubsection{Polling only}
The supernode just periodically request persistence
deltas. This would be handled over a DEALER-ROUTER pair of sockets. The nice
thing about this variant is that the subnode only has to do one thing, which is
responding to requests from the supernode(s); it does not have to proactively
send any updates after sending the an initial delta.

A big drawback is that the synchronization only happens periodically. This
does not seem to fit well into the overall Roadster architecture, which is
completely event-driven (no polls or "sleeps").

Another drawback is efficiency. This variant will periodically cause the
subnode's database to be searched for possibly large amounts of keys. Depending on the size of the
database and the efficiency of searching through keys, this could be a lot of
wasted resources or even cause bottle necks when interacting with the STOR
actor.

Overall, this variant is very simple, but does not offer some features we'd
normally expect from a framework like Roadster. The fruits are hanging low;
achieving event-driven synchronization and better efficiency is easy.

\subsubsection{Event-driven}
This variant avoids the delays introduced by the polling mechanism of the first
variant. Just like with the \gls{CSP}, the initial delta is requested and
communicated via the ROUTER-DEALER pair. As soon as the transmission of the
delta begins, the subnode also starts propagating any new modifications via the
PUSH socket. The supernode collects modifications from all subnodes through its
PULL socket.

To avoid filling the PUSH socket unnecessarily in case the supernode is
temporarily unavailable, the heartbeating done via the UPSTREAM/DOWNSTREAM actors will
be used to recognize such a situation. The continuous propagation of
modifications can be stopped, the sockets reinitialized, making the node ready
for whenever the supernode is back available.

\subsection{Chosen Variant}
No definite choice has been made yet. The client seems to favor the polling variant.
% TODO: choose a persistence synchronization variant

\section{Encryption}\label{sec:approach:encryption}
% TODO: entropy measurement
% TODO: big picture
It is fairly easy to enable transport security to secure the communication
between \zmq sockets over an unsecure network.

\subsection{Assigning socket roles}
Regarding the CURVE security mechanism in \zmq, one of the two involved sockets
needs to be designated as the CURVE server, and the other one as a CURVE
client.\footnote{This is a simple method call on each socket where the involved
keys are passed as well.} This will be done intuitively: A supernode's
DOWNSTREAM actor's sockets will act as CURVE servers, and a subnode's
UPSTREAM actor's sockets will act as CURVE clients. This is not just an
arbitrary choice: A CURVE client socket is given exactly one CURVE server
certificate. A supernode can have multiple subnodes, but the opposite is
impossible.\footnote{HA is a special case, see
\autoref{sec:approach:encryption:ha}} Thus, the socket inside the supernode's
DOWNSTREAM actor will be designated as the CURVE server, and the sockets
inside the subnodes' DOWNSTREAM actors will be designated as the CURVE
clients. An example of the client side is shown in \autoref{lst:auth:fednf}, as
performed by the UPSTREAM actor.

\begin{listing}
	\inputminted[bgcolor=bg]{Ruby}{listings/auth/fednf.rb}
	\caption{Enabling CURVE mechanism on the client.}
	\label{lst:auth:fednf}
\end{listing}

\subsection{Mutual authentication}
% keys on both sides, and which nodes need whose public key
In addition to the server authentication, which is always performed, client
side authentification is desired. This means that each federation node must be
in possession of its respective clients' public keys.

% distribution of public keys
Public keys and the private keys are generated in pairs.  Due to
the nature of public keys, they can be distributed conveniently and safely
through the shared configuration file that defines the federation
topology.\footnote{Curve25519 public keys are only 40 ASCII characters long in
\gls{Z85} notation.}

% distribution of secret keys via SSH
However, distributing the private keys is less convenient, since they must be kept
private. This can be done via \gls{SSH}, logging into each node and generating
the key pair right on the node itself. This way, the private keys would never
even touch the network.

\subsubsection{ZAP}
A socket designated as CURVE server needs a way to authenticate arriving client
connections. This is done via an in-process \gls{ZAP} authentication handler,
as described in \autoref{sec:zmq:security}. That authentication handler
needs to be able to access all clients' public keys to be able to perform its
job.

The ZAP protocol (used between a CURVE server socket and the authentication
handler) is very simple and thus makes it possible to relay the authentication
requests from there to a central ZAP authentication handler, so all clients'
public keys could be stored and managed centrally. But that would violate the
autonomy requirement, so this idea has been discarded immediately.

CZMQ provides an authentication handler\footnote{It is simply a function
(\cpp{zauth()}) that is executed by a CZMQ actor. The whole construct is
abstracted in CZTop through \rb{CZTop::Authenticator}.} that can lookup public
keys awaiting authentication in a designated directory on the file system,
which it does by instantiating a certificate store.\footnote{That certificate
store is a class in CZMQ called \cpp{zcertstore}, represented through
\rb{CZTop::CertStore} in CZTop.} The certificate store in turn looks up the
certificates on disk by the public key in question.

There is also the possibility of providing an already instanciated certificate
store to the authentication handler. This is useful because a certificate store
allows the insertion of certificates (public keys) in-memory, avoiding the need
to load certificates from disk. This greatly simplifies the key distribution.
Public key files will not have to be copied from one node to its subnodes
anymore. Instead, they can be taken directly from the shared configuration file
that defines the federation topology. As an example, \autoref{lst:auth:fedsf}
shows how to start an authentication handler which does client authentication
as it is done inside the DOWNSTREAM actor.

\begin{listing}
	\inputminted[bgcolor=bg]{Ruby}{listings/auth/fedsf.rb}
	\caption{Enabling CURVE mechanism on the server to perform client authentication.}
	\label{lst:auth:fedsf}
\end{listing}

\paragraph{Failover}\label{sec:approach:encryption:ha}
It is possible that a node's supernode is actually a HA cluster consisting of
two nodes. Those two nodes should have their own key pairs for additional
security. This imposes a problem for the subnodes: It is only possible to assign
a single CURVE server certificate (public key). In case the active HA peer becomes
unresponsive and the subnode(s) falls back to the passive HA peer, a new CURVE
server certificate needs to be assigned to the client sockets. This should be
possible. But there's a better solution:
Since the socket could be \cite[Binary Star Implementation, Binary Star client
in C]{zmq:zguide} ``confused''\footnote{This probably applies only to REQ
sockets, since they implement \cite[Client-Side Reliability (Lazy Pirate
Pattern)]{zmq:zguide} ``a small finite-state machine to enforce the
send/receive ping-pong''}, it is good practice to simply destroy the existing
socket and create a fresh one, assigning the correct supernode's CURVE server
certificate to it.

\paragraph{IP based access control}
In addition to the CURVE mechanism, blacklisting or whitelisting clients based
on their \gls{IP} addresses is possible and supported by
\rb{CZTop::Authenticator} through the PLAIN mechanism. It would even be
feasible to whitelist the exact client IP addresses, since they can be deduced
from the shared configuration. But it is not part of requirements and thus will not
be done within the scope of this bachelor thesis.

\subsection{Key generation and distribution procedure}
The following procedure can be followed to generate the required keys in
advance and make them available through the shared configuration file:

\begin{enumerate}
	\item for all nodes
	\begin{enumerate}
		\item generate key pair on the node itself and save it on the
			node
		\item remember the public key
	\end{enumerate}

	\item put all public keys (in Z85 notation) to their respective section
		in the shared config file defining the federation topology
\end{enumerate}

This procedure could be implemented as a script that performs the procedure
over \gls{SSH} while the nodes are still in the
lab (assuming that is secure). Of course that script could also be used when
the nodes are already installed in a production environment. However, for that to be
secure, the nodes' authenticities must have been established in advance, or
man-in-the-middle attacks would be possible while logging into the nodes,
compromising everything.

% TODO: `roadster keygen CONFIG` util

% TODO 256 bit encryption
% TODO 16 byte authenticator
% TODO 24 byte nonce

% TODO Entropy without encryption:
% ```
% Entropy = 5.390141 bits per byte.
% 
% Optimum compression would reduce the size
% of this 4518 byte file by 32 percent.
% 
% Chi square distribution for 4518 samples is 36298.08, and randomly
% would exceed this value less than 0.01 percent of the times.
% 
% Arithmetic mean value of data bytes is 83.2517 (127.5 = random).
% Monte Carlo value for Pi is 4.000000000 (error 27.32 percent).
% Serial correlation coefficient is 0.310227 (totally uncorrelated = 0.0).
% ```


\subsection{End-to-end security}
Encrypting and authenticating network traffic is good, but it only secures the
communication between two neighboring nodes. Messages could travel via multiple
hops to reach their destination node. To provide end-to-end security for such
messages, they need to be authenticated as well, using cryptographic
signatures.

The challenge here is to decide on what to sign. Ruby objects are serialized
into \glspl{BLOB}, which is perfectly suitable as input for a \gls{MAC} algorithm.
This is possible because the message's on-wire
representation doesn't change from origin to destination.

The codecs implemented in Roadster, which serialize a message into the an
on-wire representation, are part of the messaging layer. This fact makes it
hard to adapt the existing codecs to add authentication. The codecs should be
the final authority before the message is sent via a socket, and should be the
first to inspect an arriving message. The advantage is that a forged,
unauthentic message can (and must) be discarded immediately, without even
decoding it.  Because Ruby marshalling allows the serialization and
deserialization of almost any object, merely decoding a message could be
dangerous, as described by the Ruby documentation itself on \cite[Security
considerations]{rb:doc:marshal}.  For this reason, the codecs need to be moved
from the messaging layer down to the reactor layer.


\subsubsection{Implementation}
The codecs have been adapted to sign \emph{tag} and authenticate messages using
an authenticator object, an instance of the
new class\\\sh{Roadster::Actors::MessageAuthenticator}. It offers the two
instance methods \mintinline[bgcolor=bg]{Text};#tag; and \mintinline[bgcolor=bg]{Text};#authenticate!;.
Codecs --- which are stateless, only offering \sh{.encode} and \sh{.decode}
class methods --- are passed the authenticator object.

The resulting MAC \emph{security tag} is stored in an additional \zmq frame
before the message BLOB itself. Thus, the codec version (sent in the first
frame of every message) has been updated to represent the incompatible change.
It is important that the new frame is only used as a MAC and not any other
information, as the authenticity of any other information cannot be verified.

Intra-node messages do not have to be authenticated, whereas inter-node
messages have to be. This requires some logic to be present in the codecs
to only use the authenticator on inter-node sockets. To reduce
code complexity, and also because codecs have no knowledge about sockets, the
\emph{Null Object} design pattern has been used. When a socket is passed a
message to be sent, or when receiving a message, the appropriate authenticator
object is passed, which is either an instance of
\sh{Roadster::Actors::MessageAuthenticator} for inter-node sockets, or
\sh{Roadster::Actors::MessageAuthenticator::Null} for intra-node sockets.


\section{OPC UA Interface: High availability}\label{sec:approach:opc-ua}
Some client systems interact with Roadster over the standardized \gls{opc-ua}
interface. According to the standard in \cite[6.4.2 Server Redundancy,
p.~94]{opc-ua:behavior:server-redundancy}, there are multiple ways to ensure
interoperability when running the root node as a \gls{HA} cluster. The variant
which comes closest to the \gls{HA} mechanism favored in the original task description is
\emph{Non-transparent server Redundancy}, where the client system is aware of
the hot-standby setup. Specifically, it also has to be aware of the failover
mode. Described failover modes in the standard are \emph{Cold}, \emph{Warm},
\emph{Hot} and \emph{HotPlusMirrored}. The mode \emph{Warm} describes the
favored failover mode best, quoting \cite[6.4.2.4.4 Server Failover Modes,
p.~98]{opc-ua:behavior:server-redundancy}:


\begin{quote}
``Warm Failover mode is where the backup Server(s) can be active, but cannot
connect to actual data points (typically, a system where the underlying devices
are limited to a single connection). Underlying devices, such as PLCs, may have
limited resources that permit a single Server connection. Therefore, only a
single Server will be able to consume data. The ServiceLevel Variable defined
in Part 5 indicates the ability of the Server to provide its data to the
Client.''
\end{quote}

The concept to induce a failover in a \gls{HA} cluster (limited to a
Roadster federation only, excluding client systems) as part of the
COMM.UPSTREAM actor's responsibilities can actually be implemented in any other
actor, e.g. an adapter facing client systems. All the adapter on the passive
node has to do is send a vote to the COMM.BSTAR actor in case the client system
tries to connect and request a service. The following code would be sufficient:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Ruby}
msg = Messaging::BSP::Messages::Vote.new 'comm.opcua', 'comm.bstar'
route_message msg
  \end{minted}
  \caption{OPC-UA adapter: How to send a vote to the BSTAR actor.}
  \label{lst:approach:opc-ua}
\end{listing}

mindclue GmbH actually offers an adapter implementing the \gls{opc-ua}
interface, wrapped into a Ruby software package. Unfortunately, an
incompatibility in the package's dependencies, makes its use impossible at the
moment. Instead, an implementation of a simple Telnet server is planned. The
server shall recognize the command \sh{VOTE!}, and perform the required steps to
relay the vote to the COMM.BSTAR actor.
